{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.9.0', '2.1.6-tf')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Dense,Flatten,Softmax,Embedding,Reshape,SimpleRNN,GRU,LSTM\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__, K.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_arr = [c for c in 'abcdefghijklmnopqrstuvwxyz']\n",
    "word_dict = {n: i for i, n in enumerate(char_arr)}\n",
    "number_dict = {i: w for i, w in enumerate(char_arr)}\n",
    "n_class = len(word_dict) # number of class(=number of vocab)\n",
    "\n",
    "seq_data = ['make', 'need', 'coal', 'word', 'love', 'hate', 'live', 'home', 'hash', 'star']\n",
    "\n",
    "# TextLSTM Parameters\n",
    "n_step = 3\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(seq_data):\n",
    "    input_batch, target_batch = [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        input = [word_dict[n] for n in seq[:-1]] # 'm', 'a' , 'k' is input\n",
    "        target = word_dict[seq[-1]] # 'e' is target\n",
    "        input_batch.append(np.eye(n_class)[input])\n",
    "        target_batch.append(np.eye(n_class)[target])\n",
    "\n",
    "    return np.array(input_batch), np.array(target_batch)\n",
    "input_batch, target_batch = make_batch(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextLSTM Parameter\n",
    "n_step = 2 # number of cells (=number of Step)\n",
    "n_hidden = 5 # number of hidden units in on cell\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden))# output shape [batch_size, n_step, n_hidden])\n",
    "model.add(Dense(n_class,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 64ms/step - loss: 3.2587 - acc: 0.1000\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 384us/step - loss: 3.2558 - acc: 0.1000\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 607us/step - loss: 3.2530 - acc: 0.1000\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 530us/step - loss: 3.2501 - acc: 0.1000\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 437us/step - loss: 3.2472 - acc: 0.1000\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 576us/step - loss: 3.2443 - acc: 0.1000\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 581us/step - loss: 3.2414 - acc: 0.1000\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 750us/step - loss: 3.2385 - acc: 0.1000\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 373us/step - loss: 3.2356 - acc: 0.1000\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 737us/step - loss: 3.2326 - acc: 0.1000\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 490us/step - loss: 3.2297 - acc: 0.1000\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 403us/step - loss: 3.2267 - acc: 0.1000\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 781us/step - loss: 3.2237 - acc: 0.1000\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 356us/step - loss: 3.2208 - acc: 0.1000\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 533us/step - loss: 3.2178 - acc: 0.1000\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 475us/step - loss: 3.2148 - acc: 0.1000\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 465us/step - loss: 3.2117 - acc: 0.1000\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 609us/step - loss: 3.2087 - acc: 0.1000\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 488us/step - loss: 3.2057 - acc: 0.1000\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 755us/step - loss: 3.2026 - acc: 0.1000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 351us/step - loss: 3.1995 - acc: 0.1000\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 486us/step - loss: 3.1964 - acc: 0.1000\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 804us/step - loss: 3.1933 - acc: 0.2000\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 358us/step - loss: 3.1902 - acc: 0.2000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 657us/step - loss: 3.1870 - acc: 0.2000\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 454us/step - loss: 3.1839 - acc: 0.2000\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 408us/step - loss: 3.1807 - acc: 0.3000\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 651us/step - loss: 3.1775 - acc: 0.3000\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 418us/step - loss: 3.1742 - acc: 0.3000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 547us/step - loss: 3.1710 - acc: 0.3000\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 392us/step - loss: 3.1677 - acc: 0.3000\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 602us/step - loss: 3.1644 - acc: 0.3000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 719us/step - loss: 3.1611 - acc: 0.3000\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 352us/step - loss: 3.1577 - acc: 0.3000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 479us/step - loss: 3.1543 - acc: 0.3000\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 711us/step - loss: 3.1509 - acc: 0.3000\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 433us/step - loss: 3.1475 - acc: 0.3000\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 728us/step - loss: 3.1440 - acc: 0.3000\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 359us/step - loss: 3.1405 - acc: 0.3000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 542us/step - loss: 3.1370 - acc: 0.4000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 674us/step - loss: 3.1335 - acc: 0.4000\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 384us/step - loss: 3.1299 - acc: 0.4000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.1263 - acc: 0.4000\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 412us/step - loss: 3.1226 - acc: 0.4000\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 725us/step - loss: 3.1190 - acc: 0.5000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 503us/step - loss: 3.1153 - acc: 0.5000\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 774us/step - loss: 3.1115 - acc: 0.5000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 379us/step - loss: 3.1077 - acc: 0.5000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 360us/step - loss: 3.1039 - acc: 0.5000\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 832us/step - loss: 3.1000 - acc: 0.5000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 503us/step - loss: 3.0961 - acc: 0.5000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 696us/step - loss: 3.0922 - acc: 0.5000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 382us/step - loss: 3.0882 - acc: 0.5000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 361us/step - loss: 3.0841 - acc: 0.5000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 510us/step - loss: 3.0801 - acc: 0.5000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 427us/step - loss: 3.0760 - acc: 0.5000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 657us/step - loss: 3.0718 - acc: 0.5000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 344us/step - loss: 3.0676 - acc: 0.5000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 393us/step - loss: 3.0634 - acc: 0.5000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 624us/step - loss: 3.0591 - acc: 0.5000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 462us/step - loss: 3.0547 - acc: 0.5000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 779us/step - loss: 3.0503 - acc: 0.5000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 383us/step - loss: 3.0459 - acc: 0.5000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 537us/step - loss: 3.0414 - acc: 0.5000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 691us/step - loss: 3.0368 - acc: 0.5000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 370us/step - loss: 3.0322 - acc: 0.5000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 703us/step - loss: 3.0276 - acc: 0.5000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 463us/step - loss: 3.0228 - acc: 0.5000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 379us/step - loss: 3.0181 - acc: 0.5000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 660us/step - loss: 3.0132 - acc: 0.5000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 359us/step - loss: 3.0083 - acc: 0.5000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 451us/step - loss: 3.0034 - acc: 0.5000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 486us/step - loss: 2.9983 - acc: 0.5000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 337us/step - loss: 2.9933 - acc: 0.5000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 725us/step - loss: 2.9881 - acc: 0.5000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 356us/step - loss: 2.9829 - acc: 0.5000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 360us/step - loss: 2.9776 - acc: 0.5000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 384us/step - loss: 2.9723 - acc: 0.5000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 366us/step - loss: 2.9669 - acc: 0.5000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 389us/step - loss: 2.9614 - acc: 0.5000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 377us/step - loss: 2.9559 - acc: 0.6000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 464us/step - loss: 2.9503 - acc: 0.6000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 397us/step - loss: 2.9446 - acc: 0.6000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 384us/step - loss: 2.9388 - acc: 0.6000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 539us/step - loss: 2.9330 - acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 402us/step - loss: 2.9271 - acc: 0.6000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 367us/step - loss: 2.9211 - acc: 0.6000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 606us/step - loss: 2.9150 - acc: 0.6000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 336us/step - loss: 2.9089 - acc: 0.6000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 417us/step - loss: 2.9026 - acc: 0.6000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 574us/step - loss: 2.8963 - acc: 0.6000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 402us/step - loss: 2.8899 - acc: 0.6000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 369us/step - loss: 2.8835 - acc: 0.6000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 578us/step - loss: 2.8769 - acc: 0.6000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 390us/step - loss: 2.8703 - acc: 0.6000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 334us/step - loss: 2.8636 - acc: 0.5000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 614us/step - loss: 2.8567 - acc: 0.5000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 396us/step - loss: 2.8499 - acc: 0.5000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 364us/step - loss: 2.8429 - acc: 0.6000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 653us/step - loss: 2.8358 - acc: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56404236d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_batch, target_batch, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mak', 'nee', 'coa', 'wor', 'lov', 'hat', 'liv', 'hom', 'has', 'sta'] -> ['d', 'd', 'd', 'd', 'e', 'e', 'e', 'e', 'e', 'd']\n"
     ]
    }
   ],
   "source": [
    "inputs = [sen[:3] for sen in seq_data]\n",
    "\n",
    "predict = model.predict(input_batch)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "print(inputs, '->', [number_dict[n] for n in predict])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
